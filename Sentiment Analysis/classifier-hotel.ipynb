{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/avishek-hotel/sentiments.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The premises are very peaceful and well mainta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5 min drive out of Pisa or you need to catch t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My family of 5 stayed at the residence San Ros...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We stayed here for a couple of nights on the w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The accomodation was simple but more than adeq...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  review\n",
       "0  The premises are very peaceful and well mainta...       1\n",
       "1  5 min drive out of Pisa or you need to catch t...       0\n",
       "2  My family of 5 stayed at the residence San Ros...       1\n",
       "3  We stayed here for a couple of nights on the w...       1\n",
       "4  The accomodation was simple but more than adeq...       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"/kaggle/input/avishek-hotel/sentiments.csv\",encoding='ISO-8859–1',header=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[ df['review'] ==1, 'review'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[ df['review'] ==0, 'review'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[ df['review'] ==-1, 'review'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The premises are very peaceful and well mainta...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5 min drive out of Pisa or you need to catch t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My family of 5 stayed at the residence San Ros...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We stayed here for a couple of nights on the w...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The accomodation was simple but more than adeq...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58607</th>\n",
       "      <td>It is hard for me to review an oceanfront hote...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58608</th>\n",
       "      <td>I live close by, and needed to stay somewhere ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58609</th>\n",
       "      <td>Rolled in 11:30 laid out heads down woke up to...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58610</th>\n",
       "      <td>Absolutely terrible..I was told I was being gi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58611</th>\n",
       "      <td>Filthy, outdated, noisy neighbours, but this w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58612 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  review\n",
       "0      The premises are very peaceful and well mainta...       2\n",
       "1      5 min drive out of Pisa or you need to catch t...       1\n",
       "2      My family of 5 stayed at the residence San Ros...       2\n",
       "3      We stayed here for a couple of nights on the w...       2\n",
       "4      The accomodation was simple but more than adeq...       2\n",
       "...                                                  ...     ...\n",
       "58607  It is hard for me to review an oceanfront hote...       1\n",
       "58608  I live close by, and needed to stay somewhere ...       2\n",
       "58609  Rolled in 11:30 laid out heads down woke up to...       2\n",
       "58610  Absolutely terrible..I was told I was being gi...       0\n",
       "58611  Filthy, outdated, noisy neighbours, but this w...       0\n",
       "\n",
       "[58612 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the wordnet object value corresponding to the POS tag\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(pos_tag):\n",
    "    if pos_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif pos_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif pos_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif pos_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "    \n",
    "import string\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def clean_text(text):\n",
    "    # lower text\n",
    "    text = text.lower()\n",
    "    # tokenize text and remove puncutation\n",
    "    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n",
    "    # remove words that contain numbers\n",
    "    text = [word for word in text if not any(c.isdigit() for c in word)]\n",
    "    # remove stop words\n",
    "    stop = stopwords.words('english')\n",
    "    text = [x for x in text if x not in stop]\n",
    "    # remove empty tokens\n",
    "    text = [t for t in text if len(t) > 0]\n",
    "    # pos tag text\n",
    "    pos_tags = pos_tag(text)\n",
    "    # lemmatize text\n",
    "    text = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]\n",
    "    # remove words with only one letter\n",
    "    text = [t for t in text if len(t) > 1]\n",
    "    # join all\n",
    "    text = \" \".join(text)\n",
    "    return(text)\n",
    "\n",
    "# clean text data\n",
    "df[\"text_clean\"] = df[\"text\"].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create doc2vec vector columns\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(df[\"text_clean\"].apply(lambda x: x.split(\" \")))]\n",
    "\n",
    "# train a Doc2Vec model with our text data\n",
    "model = Doc2Vec(documents, vector_size=5, window=2, min_count=1, workers=4)\n",
    "\n",
    "# transform each document into a vector data\n",
    "doc2vec_df = df[\"text_clean\"].apply(lambda x: model.infer_vector(x.split(\" \"))).apply(pd.Series)\n",
    "doc2vec_df.columns = [\"doc2vec_vector_\" + str(x) for x in doc2vec_df.columns]\n",
    "df = pd.concat([df, doc2vec_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add number of characters column\n",
    "df[\"nb_chars\"] = df[\"text\"].apply(lambda x: len(x))\n",
    "\n",
    "# add number of words column\n",
    "df[\"nb_words\"] = df[\"text\"].apply(lambda x: len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add tf-idfs columns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(min_df = 10)\n",
    "tfidf_result = tfidf.fit_transform(df[\"text_clean\"]).toarray()\n",
    "tfidf_df = pd.DataFrame(tfidf_result, columns = tfidf.get_feature_names())\n",
    "tfidf_df.columns = [\"word_\" + str(x) for x in tfidf_df.columns]\n",
    "tfidf_df.index = df.index\n",
    "df = pd.concat([df, tfidf_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>review</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>doc2vec_vector_0</th>\n",
       "      <th>doc2vec_vector_1</th>\n",
       "      <th>doc2vec_vector_2</th>\n",
       "      <th>doc2vec_vector_3</th>\n",
       "      <th>doc2vec_vector_4</th>\n",
       "      <th>nb_chars</th>\n",
       "      <th>nb_words</th>\n",
       "      <th>...</th>\n",
       "      <th>word_yunker</th>\n",
       "      <th>word_yup</th>\n",
       "      <th>word_zealand</th>\n",
       "      <th>word_zen</th>\n",
       "      <th>word_zero</th>\n",
       "      <th>word_zip</th>\n",
       "      <th>word_zone</th>\n",
       "      <th>word_zoo</th>\n",
       "      <th>word_ztl</th>\n",
       "      <th>word_ÿthe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The premises are very peaceful and well mainta...</td>\n",
       "      <td>2</td>\n",
       "      <td>premise peaceful well maintain apartment spaci...</td>\n",
       "      <td>0.019709</td>\n",
       "      <td>0.010353</td>\n",
       "      <td>-0.178592</td>\n",
       "      <td>0.031814</td>\n",
       "      <td>0.049317</td>\n",
       "      <td>576</td>\n",
       "      <td>97</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5 min drive out of Pisa or you need to catch t...</td>\n",
       "      <td>1</td>\n",
       "      <td>min drive pisa need catch bus far walk.beautif...</td>\n",
       "      <td>0.036190</td>\n",
       "      <td>-0.164353</td>\n",
       "      <td>-0.181781</td>\n",
       "      <td>0.158485</td>\n",
       "      <td>0.152218</td>\n",
       "      <td>208</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My family of 5 stayed at the residence San Ros...</td>\n",
       "      <td>2</td>\n",
       "      <td>family stay residence san rossore night great ...</td>\n",
       "      <td>0.089884</td>\n",
       "      <td>0.013429</td>\n",
       "      <td>0.207337</td>\n",
       "      <td>-0.239732</td>\n",
       "      <td>0.150019</td>\n",
       "      <td>753</td>\n",
       "      <td>138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We stayed here for a couple of nights on the w...</td>\n",
       "      <td>2</td>\n",
       "      <td>stayed couple night way tuscany amp need somew...</td>\n",
       "      <td>-0.040634</td>\n",
       "      <td>0.068628</td>\n",
       "      <td>0.200889</td>\n",
       "      <td>-0.090924</td>\n",
       "      <td>0.109411</td>\n",
       "      <td>594</td>\n",
       "      <td>110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The accomodation was simple but more than adeq...</td>\n",
       "      <td>2</td>\n",
       "      <td>accomodation simple adequate spotlessly clean ...</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>-0.010359</td>\n",
       "      <td>-0.147511</td>\n",
       "      <td>0.130542</td>\n",
       "      <td>0.067796</td>\n",
       "      <td>337</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58607</th>\n",
       "      <td>It is hard for me to review an oceanfront hote...</td>\n",
       "      <td>1</td>\n",
       "      <td>hard review oceanfront hotel go ocean necessar...</td>\n",
       "      <td>0.007996</td>\n",
       "      <td>0.112804</td>\n",
       "      <td>-0.006084</td>\n",
       "      <td>0.136191</td>\n",
       "      <td>-0.068845</td>\n",
       "      <td>339</td>\n",
       "      <td>61</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58608</th>\n",
       "      <td>I live close by, and needed to stay somewhere ...</td>\n",
       "      <td>2</td>\n",
       "      <td>live close need stay somewhere night due renov...</td>\n",
       "      <td>-0.053087</td>\n",
       "      <td>0.104279</td>\n",
       "      <td>-0.121130</td>\n",
       "      <td>0.044849</td>\n",
       "      <td>-0.040387</td>\n",
       "      <td>315</td>\n",
       "      <td>61</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58609</th>\n",
       "      <td>Rolled in 11:30 laid out heads down woke up to...</td>\n",
       "      <td>2</td>\n",
       "      <td>roll laid head wake continental breakfast roll...</td>\n",
       "      <td>-0.099000</td>\n",
       "      <td>0.048321</td>\n",
       "      <td>0.013396</td>\n",
       "      <td>0.002030</td>\n",
       "      <td>0.156232</td>\n",
       "      <td>239</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58610</th>\n",
       "      <td>Absolutely terrible..I was told I was being gi...</td>\n",
       "      <td>0</td>\n",
       "      <td>absolutely terrible..i tell give non smoke roo...</td>\n",
       "      <td>-0.289175</td>\n",
       "      <td>-0.179853</td>\n",
       "      <td>-0.236936</td>\n",
       "      <td>0.123757</td>\n",
       "      <td>0.147060</td>\n",
       "      <td>338</td>\n",
       "      <td>61</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58611</th>\n",
       "      <td>Filthy, outdated, noisy neighbours, but this w...</td>\n",
       "      <td>0</td>\n",
       "      <td>filthy outdated noisy neighbour worst nearly e...</td>\n",
       "      <td>-0.162719</td>\n",
       "      <td>-0.036168</td>\n",
       "      <td>-0.107802</td>\n",
       "      <td>0.023930</td>\n",
       "      <td>-0.274692</td>\n",
       "      <td>224</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58612 rows × 8892 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  review  \\\n",
       "0      The premises are very peaceful and well mainta...       2   \n",
       "1      5 min drive out of Pisa or you need to catch t...       1   \n",
       "2      My family of 5 stayed at the residence San Ros...       2   \n",
       "3      We stayed here for a couple of nights on the w...       2   \n",
       "4      The accomodation was simple but more than adeq...       2   \n",
       "...                                                  ...     ...   \n",
       "58607  It is hard for me to review an oceanfront hote...       1   \n",
       "58608  I live close by, and needed to stay somewhere ...       2   \n",
       "58609  Rolled in 11:30 laid out heads down woke up to...       2   \n",
       "58610  Absolutely terrible..I was told I was being gi...       0   \n",
       "58611  Filthy, outdated, noisy neighbours, but this w...       0   \n",
       "\n",
       "                                              text_clean  doc2vec_vector_0  \\\n",
       "0      premise peaceful well maintain apartment spaci...          0.019709   \n",
       "1      min drive pisa need catch bus far walk.beautif...          0.036190   \n",
       "2      family stay residence san rossore night great ...          0.089884   \n",
       "3      stayed couple night way tuscany amp need somew...         -0.040634   \n",
       "4      accomodation simple adequate spotlessly clean ...          0.001089   \n",
       "...                                                  ...               ...   \n",
       "58607  hard review oceanfront hotel go ocean necessar...          0.007996   \n",
       "58608  live close need stay somewhere night due renov...         -0.053087   \n",
       "58609  roll laid head wake continental breakfast roll...         -0.099000   \n",
       "58610  absolutely terrible..i tell give non smoke roo...         -0.289175   \n",
       "58611  filthy outdated noisy neighbour worst nearly e...         -0.162719   \n",
       "\n",
       "       doc2vec_vector_1  doc2vec_vector_2  doc2vec_vector_3  doc2vec_vector_4  \\\n",
       "0              0.010353         -0.178592          0.031814          0.049317   \n",
       "1             -0.164353         -0.181781          0.158485          0.152218   \n",
       "2              0.013429          0.207337         -0.239732          0.150019   \n",
       "3              0.068628          0.200889         -0.090924          0.109411   \n",
       "4             -0.010359         -0.147511          0.130542          0.067796   \n",
       "...                 ...               ...               ...               ...   \n",
       "58607          0.112804         -0.006084          0.136191         -0.068845   \n",
       "58608          0.104279         -0.121130          0.044849         -0.040387   \n",
       "58609          0.048321          0.013396          0.002030          0.156232   \n",
       "58610         -0.179853         -0.236936          0.123757          0.147060   \n",
       "58611         -0.036168         -0.107802          0.023930         -0.274692   \n",
       "\n",
       "       nb_chars  nb_words  ...  word_yunker  word_yup  word_zealand  word_zen  \\\n",
       "0           576        97  ...          0.0       0.0           0.0       0.0   \n",
       "1           208        35  ...          0.0       0.0           0.0       0.0   \n",
       "2           753       138  ...          0.0       0.0           0.0       0.0   \n",
       "3           594       110  ...          0.0       0.0           0.0       0.0   \n",
       "4           337        59  ...          0.0       0.0           0.0       0.0   \n",
       "...         ...       ...  ...          ...       ...           ...       ...   \n",
       "58607       339        61  ...          0.0       0.0           0.0       0.0   \n",
       "58608       315        61  ...          0.0       0.0           0.0       0.0   \n",
       "58609       239        44  ...          0.0       0.0           0.0       0.0   \n",
       "58610       338        61  ...          0.0       0.0           0.0       0.0   \n",
       "58611       224        40  ...          0.0       0.0           0.0       0.0   \n",
       "\n",
       "       word_zero  word_zip  word_zone  word_zoo  word_ztl  word_ÿthe  \n",
       "0            0.0       0.0        0.0       0.0       0.0        0.0  \n",
       "1            0.0       0.0        0.0       0.0       0.0        0.0  \n",
       "2            0.0       0.0        0.0       0.0       0.0        0.0  \n",
       "3            0.0       0.0        0.0       0.0       0.0        0.0  \n",
       "4            0.0       0.0        0.0       0.0       0.0        0.0  \n",
       "...          ...       ...        ...       ...       ...        ...  \n",
       "58607        0.0       0.0        0.0       0.0       0.0        0.0  \n",
       "58608        0.0       0.0        0.0       0.0       0.0        0.0  \n",
       "58609        0.0       0.0        0.0       0.0       0.0        0.0  \n",
       "58610        0.0       0.0        0.0       0.0       0.0        0.0  \n",
       "58611        0.0       0.0        0.0       0.0       0.0        0.0  \n",
       "\n",
       "[58612 rows x 8892 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"review\"\n",
    "ignore_cols = [label, \"text\", \"text_clean\"]\n",
    "features = [c for c in df.columns if c not in ignore_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'review' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-8e3c6cf6f05d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'review' is not defined"
     ]
    }
   ],
   "source": [
    "# split the data into train and test\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[features], df[review], test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4cd4ce02f253>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train a random forest classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# show feature importance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# train a random forest classifier\n",
    "rf = RandomForestClassifier(n_estimators = 100, random_state = 42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# show feature importance\n",
    "feature_importances_df = pd.DataFrame({\"feature\": features, \"importance\": rf.feature_importances_}).sort_values(\"importance\", ascending = False)\n",
    "feature_importances_df.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
