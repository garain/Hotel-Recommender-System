{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "100  3727  100  3727    0     0  49039      0 --:--:-- --:--:-- --:--:-- 49693\r\n",
      "Updating TPU and VM. This may take around 2 minutes.\r\n",
      "Updating TPU runtime to pytorch-dev20200325 ...\r\n",
      "Found existing installation: torch 1.4.0\r\n",
      "Uninstalling torch-1.4.0:\r\n",
      "Done updating TPU runtime: <Response [200]>\r\n",
      "  Successfully uninstalled torch-1.4.0\r\n",
      "Found existing installation: torchvision 0.5.0\r\n",
      "Uninstalling torchvision-0.5.0:\r\n",
      "  Successfully uninstalled torchvision-0.5.0\r\n",
      "Copying gs://tpu-pytorch/wheels/torch-nightly+20200325-cp36-cp36m-linux_x86_64.whl...\r\n",
      "\r\n",
      "Operation completed over 1 objects/83.4 MiB.                                     \r\n",
      "Copying gs://tpu-pytorch/wheels/torch_xla-nightly+20200325-cp36-cp36m-linux_x86_64.whl...\r\n",
      "\r\n",
      "Operation completed over 1 objects/114.5 MiB.                                    \r\n",
      "Copying gs://tpu-pytorch/wheels/torchvision-nightly+20200325-cp36-cp36m-linux_x86_64.whl...\r\n",
      "\r\n",
      "Operation completed over 1 objects/2.5 MiB.                                      \r\n",
      "Processing ./torch-nightly+20200325-cp36-cp36m-linux_x86_64.whl\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.6/site-packages (from torch==nightly+20200325) (0.18.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from torch==nightly+20200325) (1.18.2)\r\n",
      "\u001b[31mERROR: fastai 1.0.60 requires torchvision, which is not installed.\u001b[0m\r\n",
      "\u001b[31mERROR: catalyst 20.3.3 requires torchvision>=0.2.1, which is not installed.\u001b[0m\r\n",
      "\u001b[31mERROR: allennlp 0.9.0 has requirement spacy<2.2,>=2.1.0, but you'll have spacy 2.2.3 which is incompatible.\u001b[0m\r\n",
      "Installing collected packages: torch\r\n",
      "Successfully installed torch-1.5.0a0+d6149a7\r\n",
      "Processing ./torch_xla-nightly+20200325-cp36-cp36m-linux_x86_64.whl\r\n",
      "Installing collected packages: torch-xla\r\n",
      "Successfully installed torch-xla-1.6+e788e5b\r\n",
      "Processing ./torchvision-nightly+20200325-cp36-cp36m-linux_x86_64.whl\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.6/site-packages (from torchvision==nightly+20200325) (1.5.0a0+d6149a7)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from torchvision==nightly+20200325) (1.14.0)\r\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.6/site-packages (from torchvision==nightly+20200325) (5.4.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from torchvision==nightly+20200325) (1.18.2)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.6/site-packages (from torch->torchvision==nightly+20200325) (0.18.2)\r\n",
      "Installing collected packages: torchvision\r\n",
      "Successfully installed torchvision-0.6.0a0+3c254fb\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "The following additional packages will be installed:\r\n",
      "  gfortran gfortran-6 libblas-common libblas-dev libblas3 libgfortran-6-dev\r\n",
      "  libgfortran3 libopenblas-base\r\n",
      "Suggested packages:\r\n",
      "  gfortran-multilib gfortran-doc gfortran-6-multilib gfortran-6-doc\r\n",
      "  libgfortran3-dbg libcoarrays-dev liblapack-doc-man liblapack-doc\r\n",
      "The following NEW packages will be installed:\r\n",
      "  gfortran gfortran-6 libblas-common libblas-dev libblas3 libgfortran-6-dev\r\n",
      "  libgfortran3 libomp5 libopenblas-base libopenblas-dev\r\n",
      "0 upgraded, 10 newly installed, 0 to remove and 37 not upgraded.\r\n",
      "Need to get 15.6 MB of archives.\r\n",
      "After this operation, 122 MB of additional disk space will be used.\r\n",
      "Get:1 http://deb.debian.org/debian stretch/main amd64 libgfortran3 amd64 6.3.0-18+deb9u1 [265 kB]\r\n",
      "Get:2 http://deb.debian.org/debian stretch/main amd64 libgfortran-6-dev amd64 6.3.0-18+deb9u1 [299 kB]\r\n",
      "Get:3 http://deb.debian.org/debian stretch/main amd64 gfortran-6 amd64 6.3.0-18+deb9u1 [6916 kB]\r\n",
      "Get:4 http://deb.debian.org/debian stretch/main amd64 gfortran amd64 4:6.3.0-4 [1356 B]\r\n",
      "Get:5 http://deb.debian.org/debian stretch/main amd64 libblas-common amd64 3.7.0-2 [14.2 kB]\r\n",
      "Get:6 http://deb.debian.org/debian stretch/main amd64 libblas3 amd64 3.7.0-2 [155 kB]\r\n",
      "Get:7 http://deb.debian.org/debian stretch/main amd64 libblas-dev amd64 3.7.0-2 [162 kB]\r\n",
      "Get:8 http://deb.debian.org/debian stretch/main amd64 libopenblas-base amd64 0.2.19-3 [3793 kB]\r\n",
      "Get:9 http://deb.debian.org/debian stretch/main amd64 libopenblas-dev amd64 0.2.19-3 [3809 kB]\r\n",
      "Get:10 http://deb.debian.org/debian stretch/main amd64 libomp5 amd64 3.9.1-1 [228 kB]\r\n",
      "Fetched 15.6 MB in 0s (28.1 MB/s)\r\n",
      "debconf: delaying package configuration, since apt-utils is not installed\r\n",
      "Selecting previously unselected package libgfortran3:amd64.\r\n",
      "(Reading database ... 72030 files and directories currently installed.)\r\n",
      "Preparing to unpack .../0-libgfortran3_6.3.0-18+deb9u1_amd64.deb ...\r\n",
      "Unpacking libgfortran3:amd64 (6.3.0-18+deb9u1) ...\r\n",
      "Selecting previously unselected package libgfortran-6-dev:amd64.\r\n",
      "Preparing to unpack .../1-libgfortran-6-dev_6.3.0-18+deb9u1_amd64.deb ...\r\n",
      "Unpacking libgfortran-6-dev:amd64 (6.3.0-18+deb9u1) ...\r\n",
      "Selecting previously unselected package gfortran-6.\r\n",
      "Preparing to unpack .../2-gfortran-6_6.3.0-18+deb9u1_amd64.deb ...\r\n",
      "Unpacking gfortran-6 (6.3.0-18+deb9u1) ...\r\n",
      "Selecting previously unselected package gfortran.\r\n",
      "Preparing to unpack .../3-gfortran_4%3a6.3.0-4_amd64.deb ...\r\n",
      "Unpacking gfortran (4:6.3.0-4) ...\r\n",
      "Selecting previously unselected package libblas-common.\r\n",
      "Preparing to unpack .../4-libblas-common_3.7.0-2_amd64.deb ...\r\n",
      "Unpacking libblas-common (3.7.0-2) ...\r\n",
      "Selecting previously unselected package libblas3.\r\n",
      "Preparing to unpack .../5-libblas3_3.7.0-2_amd64.deb ...\r\n",
      "Unpacking libblas3 (3.7.0-2) ...\r\n",
      "Selecting previously unselected package libblas-dev.\r\n",
      "Preparing to unpack .../6-libblas-dev_3.7.0-2_amd64.deb ...\r\n",
      "Unpacking libblas-dev (3.7.0-2) ...\r\n",
      "Selecting previously unselected package libopenblas-base.\r\n",
      "Preparing to unpack .../7-libopenblas-base_0.2.19-3_amd64.deb ...\r\n",
      "Unpacking libopenblas-base (0.2.19-3) ...\r\n",
      "Selecting previously unselected package libopenblas-dev.\r\n",
      "Preparing to unpack .../8-libopenblas-dev_0.2.19-3_amd64.deb ...\r\n",
      "Unpacking libopenblas-dev (0.2.19-3) ...\r\n",
      "Selecting previously unselected package libomp5:amd64.\r\n",
      "Preparing to unpack .../9-libomp5_3.9.1-1_amd64.deb ...\r\n",
      "Unpacking libomp5:amd64 (3.9.1-1) ...\r\n",
      "Setting up libomp5:amd64 (3.9.1-1) ...\r\n",
      "Setting up libblas-common (3.7.0-2) ...\r\n",
      "Setting up libgfortran3:amd64 (6.3.0-18+deb9u1) ...\r\n",
      "Setting up libgfortran-6-dev:amd64 (6.3.0-18+deb9u1) ...\r\n",
      "Setting up libblas3 (3.7.0-2) ...\r\n",
      "update-alternatives: using /usr/lib/libblas/libblas.so.3 to provide /usr/lib/libblas.so.3 (libblas.so.3) in auto mode\r\n",
      "Processing triggers for libc-bin (2.24-11+deb9u4) ...\r\n",
      "Setting up libopenblas-base (0.2.19-3) ...\r\n",
      "update-alternatives: using /usr/lib/openblas-base/libblas.so.3 to provide /usr/lib/libblas.so.3 (libblas.so.3) in auto mode\r\n",
      "update-alternatives: using /usr/lib/openblas-base/liblapack.so.3 to provide /usr/lib/liblapack.so.3 (liblapack.so.3) in auto mode\r\n",
      "Setting up gfortran-6 (6.3.0-18+deb9u1) ...\r\n",
      "Setting up gfortran (4:6.3.0-4) ...\r\n",
      "update-alternatives: using /usr/bin/gfortran to provide /usr/bin/f95 (f95) in auto mode\r\n",
      "update-alternatives: using /usr/bin/gfortran to provide /usr/bin/f77 (f77) in auto mode\r\n",
      "Setting up libblas-dev (3.7.0-2) ...\r\n",
      "update-alternatives: using /usr/lib/libblas/libblas.so to provide /usr/lib/libblas.so (libblas.so) in auto mode\r\n",
      "Setting up libopenblas-dev (0.2.19-3) ...\r\n",
      "update-alternatives: using /usr/lib/openblas-base/libblas.so to provide /usr/lib/libblas.so (libblas.so) in auto mode\r\n",
      "update-alternatives: using /usr/lib/openblas-base/liblapack.so to provide /usr/lib/liblapack.so (liblapack.so) in auto mode\r\n",
      "Processing triggers for libc-bin (2.24-11+deb9u4) ...\r\n"
     ]
    }
   ],
   "source": [
    "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
    "!python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/avishek-hotel/sentiments.csv\n",
      "/kaggle/input/bert-base-uncased/vocab.txt\n",
      "/kaggle/input/bert-base-uncased/config.json\n",
      "/kaggle/input/bert-base-uncased/pytorch_model.bin\n",
      "/kaggle/input/hotel-reviews/Datafiniti_Hotel_Reviews_Jun19.csv\n",
      "/kaggle/input/hotel-reviews/7282_1.csv\n",
      "/kaggle/input/hotel-reviews/Datafiniti_Hotel_Reviews.csv\n",
      "/kaggle/input/bert-base-multilingual-uncased/vocab.txt\n",
      "/kaggle/input/bert-base-multilingual-uncased/config.json\n",
      "/kaggle/input/bert-base-multilingual-uncased/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The premises are very peaceful and well mainta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5 min drive out of Pisa or you need to catch t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My family of 5 stayed at the residence San Ros...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We stayed here for a couple of nights on the w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The accomodation was simple but more than adeq...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  review\n",
       "0  The premises are very peaceful and well mainta...       1\n",
       "1  5 min drive out of Pisa or you need to catch t...       0\n",
       "2  My family of 5 stayed at the residence San Ros...       1\n",
       "3  We stayed here for a couple of nights on the w...       1\n",
       "4  The accomodation was simple but more than adeq...       1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"/kaggle/input/avishek-hotel/sentiments.csv\",encoding='ISO-8859–1',header=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df1=pd.read_csv(\"/kaggle/input/hotel-reviews/Datafiniti_Hotel_Reviews_Jun19.csv\", usecols=['reviews.text', 'reviews.rating'])\n",
    "df2=pd.read_csv(\"/kaggle/input/hotel-reviews/Datafiniti_Hotel_Reviews.csv\", usecols=['reviews.text', 'reviews.rating'])\n",
    "df3=pd.read_csv(\"/kaggle/input/hotel-reviews/7282_1.csv\", usecols=['reviews.text', 'reviews.rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([df1, df2, df3], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        3.0\n",
       "1        4.0\n",
       "2        3.0\n",
       "3        5.0\n",
       "4        2.0\n",
       "        ... \n",
       "55907    5.0\n",
       "55908    5.0\n",
       "55909    5.0\n",
       "55910    0.0\n",
       "55911    0.0\n",
       "Name: reviews.rating, Length: 55912, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"reviews.rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[ train['reviews.rating'] <2.5, 'reviews.rating'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[ train['reviews.rating'] ==2.5, 'reviews.rating'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[ train['reviews.rating'] >2.5, 'reviews.rating'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    " train=(train.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews.rating</th>\n",
       "      <th>reviews.text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>This hotel was nice and quiet. Did not know, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>We stayed in the king suite with the separatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Parking was horrible, somebody ran into my ren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Not cheap but excellent location. Price is som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>If you get the room that they advertised on th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviews.rating                                       reviews.text\n",
       "0               1  This hotel was nice and quiet. Did not know, t...\n",
       "1               1  We stayed in the king suite with the separatio...\n",
       "2               1  Parking was horrible, somebody ran into my ren...\n",
       "3               1  Not cheap but excellent location. Price is som...\n",
       "4              -1  If you get the room that they advertised on th..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"reviews.rating\"]=train[\"reviews.rating\"].astype(int)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>This hotel was nice and quiet. Did not know, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>We stayed in the king suite with the separatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Parking was horrible, somebody ran into my ren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Not cheap but excellent location. Price is som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>If you get the room that they advertised on th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review                                               text\n",
       "0       1  This hotel was nice and quiet. Did not know, t...\n",
       "1       1  We stayed in the king suite with the separatio...\n",
       "2       1  Parking was horrible, somebody ran into my ren...\n",
       "3       1  Not cheap but excellent location. Price is som...\n",
       "4      -1  If you get the room that they advertised on th..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=train.rename(columns={\"reviews.text\": \"text\", \"reviews.rating\": \"review\"})\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, valid, test = np.split(df.sample(frac=1), [int(.7*len(df)), int(.9*len(df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train=pd.concat([train,t], axis=0).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "valid=valid.rename(columns={\"text\": \"comment_text\", \"review\": \"rating\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>This hotel was nice and quiet. Did not know, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>We stayed in the king suite with the separatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Parking was horrible, somebody ran into my ren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Not cheap but excellent location. Price is som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>If you get the room that they advertised on th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                       comment_text\n",
       "0       1  This hotel was nice and quiet. Did not know, t...\n",
       "1       1  We stayed in the king suite with the separatio...\n",
       "2       1  Parking was horrible, somebody ran into my ren...\n",
       "3       1  Not cheap but excellent location. Price is som...\n",
       "4      -1  If you get the room that they advertised on th..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=train.rename(columns={\"text\": \"comment_text\", \"review\": \"rating\"})\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train[train[\"rating\"]!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>This hotel was nice and quiet. Did not know, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>We stayed in the king suite with the separatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Parking was horrible, somebody ran into my ren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Not cheap but excellent location. Price is som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>If you get the room that they advertised on th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96048</th>\n",
       "      <td>1</td>\n",
       "      <td>We stayed one night only is this quaint hotel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96049</th>\n",
       "      <td>1</td>\n",
       "      <td>WONDERFUL!!! IF YOU ARE LOOKING AT ANOTHER PLA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96050</th>\n",
       "      <td>-1</td>\n",
       "      <td>I had stayed at this hotel for 3 nights in Dec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96053</th>\n",
       "      <td>1</td>\n",
       "      <td>We have stayed in there for a night when we vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96054</th>\n",
       "      <td>1</td>\n",
       "      <td>Exactly what the friendly hotel receptionist s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90795 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rating                                       comment_text\n",
       "0           1  This hotel was nice and quiet. Did not know, t...\n",
       "1           1  We stayed in the king suite with the separatio...\n",
       "2           1  Parking was horrible, somebody ran into my ren...\n",
       "3           1  Not cheap but excellent location. Price is som...\n",
       "4          -1  If you get the room that they advertised on th...\n",
       "...       ...                                                ...\n",
       "96048       1  We stayed one night only is this quaint hotel ...\n",
       "96049       1  WONDERFUL!!! IF YOU ARE LOOKING AT ANOTHER PLA...\n",
       "96050      -1  I had stayed at this hotel for 3 nights in Dec...\n",
       "96053       1  We have stayed in there for a night when we vi...\n",
       "96054       1  Exactly what the friendly hotel receptionist s...\n",
       "\n",
       "[90795 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid=valid[valid[\"rating\"]!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56648</th>\n",
       "      <td>We enjoyed Blue Sands very much. The staff wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38003</th>\n",
       "      <td>I love this hotel. As usual when staying in Sa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6107</th>\n",
       "      <td>We??ve been in this hotel in February and was...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55541</th>\n",
       "      <td>Clean and nicely appointed. Rooms are a good s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7731</th>\n",
       "      <td>Lovely hotel ideally situated for a short walk...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55765</th>\n",
       "      <td>Can't say enough about it. Perfect spot to see...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39663</th>\n",
       "      <td>This place is in need of some serious updating...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32521</th>\n",
       "      <td>Stayed at Carleton Lodge for the first time th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6650</th>\n",
       "      <td>Our room was looking the main street and it wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19843</th>\n",
       "      <td>we've stayed many times in Quebec City, usuall...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10253 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comment_text  rating\n",
       "56648  We enjoyed Blue Sands very much. The staff wer...       1\n",
       "38003  I love this hotel. As usual when staying in Sa...       1\n",
       "6107   We??ve been in this hotel in February and was...       1\n",
       "55541  Clean and nicely appointed. Rooms are a good s...       1\n",
       "7731   Lovely hotel ideally situated for a short walk...       1\n",
       "...                                                  ...     ...\n",
       "55765  Can't say enough about it. Perfect spot to see...       1\n",
       "39663  This place is in need of some serious updating...      -1\n",
       "32521  Stayed at Carleton Lodge for the first time th...       1\n",
       "6650   Our room was looking the main street and it wa...       1\n",
       "19843  we've stayed many times in Quebec City, usuall...       1\n",
       "\n",
       "[10253 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict, namedtuple\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "import joblib\n",
    "\n",
    "import logging\n",
    "import transformers\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup, get_constant_schedule\n",
    "import sys\n",
    "from sklearn import metrics, model_selection\n",
    "\n",
    "import warnings\n",
    "import torch_xla\n",
    "import torch_xla.debug.metrics as met\n",
    "import torch_xla.distributed.data_parallel as dp\n",
    "import torch_xla.distributed.parallel_loader as pl\n",
    "import torch_xla.utils.utils as xu\n",
    "import torch_xla.core.xla_model as xm\n",
    "import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "import torch_xla.test.test_utils as test_utils\n",
    "\n",
    "class AverageMeter:\n",
    "    \"\"\"\n",
    "    Computes and stores the average and current value\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        \n",
    "    #resets the values to zero\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "    \n",
    "    #updates the values of average\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a class to convert the dataset into lowercase\n",
    "class BERTBaseUncased(nn.Module):\n",
    "    #initialization function taking the path as a parameter\n",
    "        def __init__(self, path):\n",
    "            super(BERTBaseUncased, self).__init__()\n",
    "            self.bert_path = path\n",
    "            #Instantiate a pretrained pytorch model from a pre-trained model configuration.\n",
    "            self.bert = transformers.BertModel.from_pretrained(self.bert_path)\n",
    "            #randomly sets elements to zero to prevent overfitting.\n",
    "            self.bert_drop = nn.Dropout(0.3) \n",
    "            #linear/outer layer as bert base model has 768*2 output features (bert base and multilingual) and 1 for binary classification\n",
    "            self.out = nn.Linear(768 * 2, 1)\n",
    "        \n",
    "        def forward(self,ids,mask,token_type_ids):\n",
    "            #o1 ,is the last hidden and we neglect pooler outputs of the bert \n",
    "            o1,_ = self.bert(ids,attention_mask=mask,token_type_ids=token_type_ids)\n",
    "            \n",
    "            apool = torch.mean(o1, 1)\n",
    "            mpool, _ = torch.max(o1, 1)\n",
    "            cat = torch.cat((apool, mpool), 1)\n",
    "\n",
    "            bo = self.bert_drop(cat)\n",
    "            output = self.out(bo)\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a class to accomodate the dataset to bert model\n",
    "class BERTDatasetTrain:\n",
    "    def __init__(self, comment_text,targets, tokenizer, max_length):\n",
    "        self.comment_text = comment_text\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.targets=targets\n",
    "\n",
    "    #getting the total length\n",
    "    def __len__(self):\n",
    "        return len(self.comment_text)\n",
    "    \n",
    "    #returns the token type ids from the dataset of the comment_text\n",
    "    def __getitem__(self, item):\n",
    "        #checking for the digits \n",
    "        comment_text = str(self.comment_text[item])\n",
    "        #removing all the unwanted spaces\n",
    "        comment_text = \" \".join(comment_text.split())\n",
    "\n",
    "        #encode 2 strings at a time hence 2nd string is none and add the CLS token\n",
    "        inputs = self.tokenizer.encode_plus(comment_text,None,add_special_tokens=True,max_length=self.max_length,)\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "        \n",
    "        padding_length = self.max_length - len(ids)\n",
    "        \n",
    "        ids = ids + ([0] * padding_length)\n",
    "        mask = mask + ([0] * padding_length)\n",
    "        token_type_ids = token_type_ids + ([0] * padding_length)\n",
    "        \n",
    "        return {'ids': torch.tensor(ids, dtype=torch.long),'mask': torch.tensor(mask, dtype=torch.long),'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),'targets': torch.tensor(self.targets[item], dtype=torch.float)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx = BERTBaseUncased(path=\"../input/bert-base-multilingual-uncased/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    \n",
    "    def loss_fn(outputs, targets):\n",
    "        return nn.BCEWithLogitsLoss()(outputs, targets.view(-1, 1))\n",
    "\n",
    "    def train_loop_fn(data_loader, model, optimizer, device, scheduler=None):\n",
    "        model.train()\n",
    "        for bi, d in enumerate(data_loader):\n",
    "            ids = d[\"ids\"]\n",
    "            mask = d[\"mask\"]\n",
    "            token_type_ids = d[\"token_type_ids\"]\n",
    "            targets = d[\"targets\"]\n",
    "\n",
    "            ids = ids.to(device, dtype=torch.long)\n",
    "            mask = mask.to(device, dtype=torch.long)\n",
    "            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "            targets = targets.to(device, dtype=torch.float)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(ids=ids,mask=mask,token_type_ids=token_type_ids)\n",
    "\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            if bi % 10 == 0:\n",
    "                xm.master_print(f'bi={bi}, loss={loss}')\n",
    "\n",
    "            loss.backward()\n",
    "            #Xla optimizer\n",
    "            xm.optimizer_step(optimizer)\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "\n",
    "    def eval_loop_fn(data_loader, model, device):\n",
    "        model.eval()\n",
    "        fin_targets = []\n",
    "        fin_outputs = []\n",
    "        for bi, d in enumerate(data_loader):\n",
    "            ids = d[\"ids\"]\n",
    "            mask = d[\"mask\"]\n",
    "            token_type_ids = d[\"token_type_ids\"]\n",
    "            targets = d[\"targets\"]\n",
    "\n",
    "            ids = ids.to(device, dtype=torch.long)\n",
    "            mask = mask.to(device, dtype=torch.long)\n",
    "            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "            targets = targets.to(device, dtype=torch.float)\n",
    "\n",
    "            outputs = model(\n",
    "                ids=ids,\n",
    "                mask=mask,\n",
    "                token_type_ids=token_type_ids\n",
    "            )\n",
    "\n",
    "            targets_np = targets.cpu().detach().numpy().tolist()\n",
    "            outputs_np = outputs.cpu().detach().numpy().tolist()\n",
    "            fin_targets.extend(targets_np)\n",
    "            fin_outputs.extend(outputs_np)    \n",
    "\n",
    "        return fin_outputs, fin_targets\n",
    "\n",
    "    \n",
    "    MAX_LEN = 192\n",
    "    TRAIN_BATCH_SIZE = 64\n",
    "    EPOCHS = 15\n",
    "\n",
    "    tokenizer = transformers.BertTokenizer.from_pretrained(\"../input/bert-base-multilingual-uncased/\", do_lower_case=True)\n",
    "\n",
    "    train_targets = train.rating.values\n",
    "    valid_targets = valid.rating.values\n",
    "\n",
    "    train_dataset = BERTDatasetTrain(comment_text=train.comment_text.values,targets=train_targets,tokenizer=tokenizer,max_length=MAX_LEN)\n",
    "\n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset,num_replicas=xm.xrt_world_size(),rank=xm.get_ordinal(),shuffle=True)\n",
    "\n",
    "    train_data_loader = torch.utils.data.DataLoader(train_dataset,batch_size=TRAIN_BATCH_SIZE,sampler=train_sampler,drop_last=True,num_workers=1)\n",
    "\n",
    "    valid_dataset = BERTDatasetTrain(\n",
    "        comment_text=valid.comment_text.values,\n",
    "        targets=valid_targets,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=MAX_LEN\n",
    "    )\n",
    "\n",
    "    valid_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "          valid_dataset,\n",
    "          num_replicas=xm.xrt_world_size(),\n",
    "          rank=xm.get_ordinal(),\n",
    "          shuffle=False)\n",
    "\n",
    "    valid_data_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=16,\n",
    "        sampler=valid_sampler,\n",
    "        drop_last=False,\n",
    "        num_workers=1\n",
    "    )\n",
    "\n",
    "    device = xm.xla_device()\n",
    "    model = mx.to(device)\n",
    "\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n",
    "\n",
    "    lr = 0.4 * 1e-5 * xm.xrt_world_size()\n",
    "    num_train_steps = int(len(train_dataset) / TRAIN_BATCH_SIZE / xm.xrt_world_size() * EPOCHS)\n",
    "    xm.master_print(f'num_train_steps = {num_train_steps}, world_size={xm.xrt_world_size()}')\n",
    "\n",
    "    #Adam Optimizer\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=lr)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=num_train_steps\n",
    "    )\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        para_loader = pl.ParallelLoader(train_data_loader, [device])\n",
    "        train_loop_fn(para_loader.per_device_loader(device), model, optimizer, device, scheduler=scheduler)\n",
    "\n",
    "        para_loader = pl.ParallelLoader(valid_data_loader, [device])\n",
    "        o, t = eval_loop_fn(para_loader.per_device_loader(device), model, device)\n",
    "        xm.save(model.state_dict(), \"model.bin\")\n",
    "        \n",
    "        # AUC tells how much model is capable of distinguishing between classes. \n",
    "        auc = metrics.roc_auc_score(np.array(t) >= 0.5, o)\n",
    "        xm.master_print(f'AUC = {auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_train_steps = 2660, world_size=8\n",
      "bi=0, loss=0.5737982392311096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:750: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, Number alpha)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:750: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, Number alpha)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:750: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, Number alpha)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:750: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, Number alpha)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:750: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, Number alpha)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:750: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, Number alpha)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:750: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, Number alpha)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:750: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, Number alpha)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bi=10, loss=0.34277769923210144\n",
      "bi=20, loss=0.28772637248039246\n",
      "bi=30, loss=-0.5896278023719788\n",
      "bi=40, loss=-0.04292493686079979\n",
      "bi=50, loss=-0.565065324306488\n",
      "bi=60, loss=-0.4308408200740814\n",
      "bi=70, loss=-0.10912217944860458\n",
      "bi=80, loss=-1.1541502475738525\n",
      "bi=90, loss=-0.6131142377853394\n",
      "bi=100, loss=-0.09173978865146637\n",
      "bi=110, loss=-0.7218763828277588\n",
      "bi=120, loss=-1.2719125747680664\n",
      "bi=130, loss=-0.8977183103561401\n",
      "bi=140, loss=-1.3622227907180786\n",
      "bi=150, loss=0.4561169743537903\n",
      "bi=160, loss=1.014007806777954\n",
      "bi=170, loss=0.3053668737411499\n",
      "AUC = 0.9876142131979696\n",
      "bi=0, loss=-1.4210129976272583\n",
      "bi=10, loss=0.1627686470746994\n",
      "bi=20, loss=-0.8841155767440796\n",
      "bi=30, loss=-2.7289726734161377\n",
      "bi=40, loss=-1.6477148532867432\n",
      "bi=50, loss=-1.5037308931350708\n",
      "bi=60, loss=-1.2318180799484253\n",
      "bi=70, loss=-0.6982350945472717\n",
      "bi=80, loss=-3.109071731567383\n",
      "bi=90, loss=-1.4408725500106812\n",
      "bi=100, loss=-0.7926421165466309\n",
      "bi=110, loss=-0.8305889964103699\n",
      "bi=120, loss=-2.8438165187835693\n",
      "bi=130, loss=-2.736185073852539\n",
      "bi=140, loss=-3.8358752727508545\n",
      "bi=150, loss=-1.0204551219940186\n",
      "bi=160, loss=-1.3446271419525146\n",
      "bi=170, loss=-0.38034966588020325\n",
      "AUC = 0.9877664974619289\n",
      "bi=0, loss=-2.5913407802581787\n",
      "bi=10, loss=-1.1580864191055298\n",
      "bi=20, loss=-2.4727282524108887\n",
      "bi=30, loss=-3.19024920463562\n",
      "bi=40, loss=-3.808283805847168\n",
      "bi=50, loss=-2.3529531955718994\n",
      "bi=60, loss=-3.1339120864868164\n",
      "bi=70, loss=-1.3278449773788452\n",
      "bi=80, loss=-5.336130619049072\n",
      "bi=90, loss=-2.5033090114593506\n",
      "bi=100, loss=-1.9461807012557983\n",
      "bi=110, loss=-2.701244354248047\n",
      "bi=120, loss=-4.742592811584473\n",
      "bi=130, loss=-4.560568332672119\n",
      "bi=140, loss=-5.064820289611816\n",
      "bi=150, loss=-0.8788633346557617\n",
      "bi=160, loss=-2.379343032836914\n",
      "bi=170, loss=0.6197575330734253\n",
      "AUC = 0.9864551607445009\n",
      "bi=0, loss=-4.9146623611450195\n",
      "bi=10, loss=-1.6527087688446045\n",
      "bi=20, loss=-4.736128330230713\n",
      "bi=30, loss=-8.030792236328125\n",
      "bi=40, loss=-5.187008857727051\n",
      "bi=50, loss=-5.060096740722656\n",
      "bi=60, loss=-3.905787467956543\n",
      "bi=70, loss=-2.750957489013672\n",
      "bi=80, loss=-6.728394985198975\n",
      "bi=90, loss=-4.673543453216553\n",
      "bi=100, loss=-3.8464510440826416\n",
      "bi=110, loss=-2.2348828315734863\n",
      "bi=120, loss=-8.031787872314453\n",
      "bi=130, loss=-6.2184600830078125\n",
      "bi=140, loss=-7.741705894470215\n",
      "bi=150, loss=-0.9852317571640015\n",
      "bi=160, loss=-2.5741989612579346\n",
      "bi=170, loss=-2.3579609394073486\n",
      "AUC = 0.9860829103214891\n",
      "bi=0, loss=-5.453251361846924\n",
      "bi=10, loss=-1.134955644607544\n",
      "bi=20, loss=-4.127795696258545\n",
      "bi=30, loss=-8.61686897277832\n",
      "bi=40, loss=-6.3738298416137695\n",
      "bi=50, loss=-4.87722635269165\n",
      "bi=60, loss=-5.068557262420654\n",
      "bi=70, loss=-2.4331109523773193\n",
      "bi=80, loss=-8.99794864654541\n",
      "bi=90, loss=-4.61734676361084\n",
      "bi=100, loss=-6.330757141113281\n",
      "bi=110, loss=-5.419124126434326\n",
      "bi=120, loss=-10.29820442199707\n",
      "bi=130, loss=-6.7398834228515625\n",
      "bi=140, loss=-10.282380104064941\n",
      "bi=150, loss=5.334696292877197\n",
      "bi=160, loss=-3.762436866760254\n",
      "bi=170, loss=-1.7885689735412598\n",
      "AUC = 0.9827834179357022\n",
      "bi=0, loss=-8.12904167175293\n",
      "bi=10, loss=-0.11102088540792465\n",
      "bi=20, loss=-7.675625801086426\n",
      "bi=30, loss=-10.987079620361328\n",
      "bi=40, loss=-12.774556159973145\n",
      "bi=50, loss=-5.646376609802246\n",
      "bi=60, loss=-8.927605628967285\n",
      "bi=70, loss=-2.8900609016418457\n",
      "bi=80, loss=-10.381697654724121\n",
      "bi=90, loss=-5.916932582855225\n",
      "bi=100, loss=-5.963615417480469\n",
      "bi=110, loss=-9.358903884887695\n",
      "bi=120, loss=-10.689908981323242\n",
      "bi=130, loss=-7.445619583129883\n",
      "bi=140, loss=-12.48647689819336\n",
      "bi=150, loss=-3.6928813457489014\n",
      "bi=160, loss=-5.213710308074951\n",
      "bi=170, loss=0.6896126866340637\n",
      "AUC = 0.9848307952622674\n",
      "bi=0, loss=-7.8251872062683105\n",
      "bi=10, loss=-1.3136084079742432\n",
      "bi=20, loss=-7.8541717529296875\n",
      "bi=30, loss=-16.79754066467285\n",
      "bi=40, loss=-11.55457592010498\n",
      "bi=50, loss=-8.705686569213867\n",
      "bi=60, loss=-8.448993682861328\n",
      "bi=70, loss=-3.3799376487731934\n",
      "bi=80, loss=-13.474456787109375\n",
      "bi=90, loss=-8.220745086669922\n",
      "bi=100, loss=-5.275482654571533\n",
      "bi=110, loss=-8.87113094329834\n",
      "bi=120, loss=-13.485696792602539\n",
      "bi=130, loss=-12.463217735290527\n",
      "bi=140, loss=-14.30248737335205\n",
      "bi=150, loss=-3.806447982788086\n",
      "bi=160, loss=-7.465859413146973\n",
      "bi=170, loss=-0.8857682347297668\n",
      "AUC = 0.9862774957698816\n",
      "bi=0, loss=-10.714434623718262\n",
      "bi=10, loss=-3.681920289993286\n",
      "bi=20, loss=-7.523868083953857\n",
      "bi=30, loss=-15.386957168579102\n",
      "bi=40, loss=-11.56637191772461\n",
      "bi=50, loss=-11.327245712280273\n",
      "bi=60, loss=-8.774310111999512\n",
      "bi=70, loss=-3.8269691467285156\n",
      "bi=80, loss=-15.517692565917969\n",
      "bi=90, loss=-7.5069499015808105\n",
      "bi=100, loss=-7.706066131591797\n",
      "bi=110, loss=-10.035870552062988\n",
      "bi=120, loss=-13.799659729003906\n",
      "bi=130, loss=-14.022895812988281\n",
      "bi=140, loss=-18.325773239135742\n",
      "bi=150, loss=-6.296604633331299\n",
      "bi=160, loss=-6.223077774047852\n",
      "bi=170, loss=-4.175596237182617\n",
      "AUC = 0.9849661590524534\n",
      "bi=0, loss=-11.333454132080078\n",
      "bi=10, loss=-5.9930853843688965\n",
      "bi=20, loss=-11.994377136230469\n",
      "bi=30, loss=-14.901735305786133\n",
      "bi=40, loss=-16.7071475982666\n",
      "bi=50, loss=-12.73332691192627\n",
      "bi=60, loss=-12.725129127502441\n",
      "bi=70, loss=-4.139585971832275\n",
      "bi=80, loss=-16.652511596679688\n",
      "bi=90, loss=-8.094602584838867\n",
      "bi=100, loss=-8.404784202575684\n",
      "bi=110, loss=-13.261594772338867\n",
      "bi=120, loss=-17.253971099853516\n",
      "bi=130, loss=-13.1274995803833\n",
      "bi=140, loss=-18.24713897705078\n",
      "bi=150, loss=-5.153997421264648\n",
      "bi=160, loss=-11.211214065551758\n",
      "bi=170, loss=-6.625088214874268\n",
      "AUC = 0.9846700507614212\n",
      "bi=0, loss=-13.062379837036133\n",
      "bi=10, loss=-2.3227226734161377\n",
      "bi=20, loss=-10.721368789672852\n",
      "bi=30, loss=-16.78070068359375\n",
      "bi=40, loss=-19.371923446655273\n",
      "bi=50, loss=-13.660357475280762\n",
      "bi=60, loss=-13.782844543457031\n",
      "bi=70, loss=-4.515378952026367\n",
      "bi=80, loss=-15.86257266998291\n",
      "bi=90, loss=-8.653209686279297\n",
      "bi=100, loss=-9.123870849609375\n",
      "bi=110, loss=-9.540567398071289\n",
      "bi=120, loss=-16.092172622680664\n",
      "bi=130, loss=-15.478158950805664\n",
      "bi=140, loss=-21.43076515197754\n",
      "bi=150, loss=-7.318184852600098\n",
      "bi=160, loss=-7.201063632965088\n",
      "bi=170, loss=-4.864660739898682\n",
      "AUC = 0.9868020304568527\n",
      "bi=0, loss=-11.497581481933594\n",
      "bi=10, loss=-9.268451690673828\n",
      "bi=20, loss=-16.362741470336914\n",
      "bi=30, loss=-17.421985626220703\n",
      "bi=40, loss=-21.817678451538086\n",
      "bi=50, loss=-11.93837833404541\n",
      "bi=60, loss=-12.885510444641113\n",
      "bi=70, loss=-4.7294697761535645\n",
      "bi=80, loss=-21.64849090576172\n",
      "bi=90, loss=-9.274230003356934\n",
      "bi=100, loss=-9.69120979309082\n",
      "bi=110, loss=-12.594552040100098\n",
      "bi=120, loss=-17.05081558227539\n",
      "bi=130, loss=-17.204814910888672\n",
      "bi=140, loss=-22.5775089263916\n",
      "bi=150, loss=-5.5439348220825195\n",
      "bi=160, loss=-7.607011318206787\n",
      "bi=170, loss=-9.963862419128418\n",
      "AUC = 0.9878257191201354\n",
      "bi=0, loss=-14.632335662841797\n",
      "bi=10, loss=-9.499107360839844\n",
      "bi=20, loss=-14.17444133758545\n",
      "bi=30, loss=-20.73061180114746\n",
      "bi=40, loss=-19.883647918701172\n",
      "bi=50, loss=-12.944849967956543\n",
      "bi=60, loss=-11.041794776916504\n",
      "bi=70, loss=-4.997882843017578\n",
      "bi=80, loss=-22.678115844726562\n",
      "bi=90, loss=-9.755959510803223\n",
      "bi=100, loss=-10.033787727355957\n",
      "bi=110, loss=-15.618935585021973\n",
      "bi=120, loss=-17.743192672729492\n",
      "bi=130, loss=-18.133237838745117\n",
      "bi=140, loss=-20.883779525756836\n",
      "bi=150, loss=-8.133419036865234\n",
      "bi=160, loss=-7.980052947998047\n",
      "bi=170, loss=-7.902205944061279\n",
      "AUC = 0.9858206429780034\n",
      "bi=0, loss=-15.104966163635254\n",
      "bi=10, loss=-10.034704208374023\n",
      "bi=20, loss=-15.172085762023926\n",
      "bi=30, loss=-28.819320678710938\n",
      "bi=40, loss=-20.057796478271484\n",
      "bi=50, loss=-18.26481819152832\n",
      "bi=60, loss=-16.33763313293457\n",
      "bi=70, loss=-5.159820556640625\n",
      "bi=80, loss=-23.43852424621582\n",
      "bi=90, loss=-10.166584014892578\n",
      "bi=100, loss=-14.422586441040039\n",
      "bi=110, loss=-15.930207252502441\n",
      "bi=120, loss=-18.374343872070312\n",
      "bi=130, loss=-18.64044952392578\n",
      "bi=140, loss=-22.358964920043945\n",
      "bi=150, loss=-8.47860336303711\n",
      "bi=160, loss=-8.12052059173584\n",
      "bi=170, loss=-8.105063438415527\n",
      "AUC = 0.9866074450084601\n",
      "bi=0, loss=-15.601434707641602\n",
      "bi=10, loss=-7.8618035316467285\n",
      "bi=20, loss=-15.627665519714355\n",
      "bi=30, loss=-29.856647491455078\n",
      "bi=40, loss=-22.739681243896484\n",
      "bi=50, loss=-18.657712936401367\n",
      "bi=60, loss=-17.238828659057617\n",
      "bi=70, loss=-5.259572505950928\n",
      "bi=80, loss=-23.964561462402344\n",
      "bi=90, loss=-10.211565971374512\n",
      "bi=100, loss=-10.73297119140625\n",
      "bi=110, loss=-16.359346389770508\n",
      "bi=120, loss=-18.741703033447266\n",
      "bi=130, loss=-18.962635040283203\n",
      "bi=140, loss=-24.555145263671875\n",
      "bi=150, loss=-8.582040786743164\n",
      "bi=160, loss=-8.190641403198242\n",
      "bi=170, loss=-7.546205043792725\n",
      "AUC = 0.9901099830795264\n",
      "bi=0, loss=-15.990307807922363\n",
      "bi=10, loss=-10.483591079711914\n",
      "bi=20, loss=-15.743597030639648\n",
      "bi=30, loss=-28.500207901000977\n",
      "bi=40, loss=-22.53458595275879\n",
      "bi=50, loss=-18.986385345458984\n",
      "bi=60, loss=-16.58357048034668\n",
      "bi=70, loss=-5.368541240692139\n",
      "bi=80, loss=-24.31477928161621\n",
      "bi=90, loss=-10.42821979522705\n",
      "bi=100, loss=-10.622321128845215\n",
      "bi=110, loss=-16.460025787353516\n",
      "bi=120, loss=-18.91776466369629\n",
      "bi=130, loss=-19.219642639160156\n",
      "bi=140, loss=-24.66180992126465\n",
      "bi=150, loss=-8.565332412719727\n",
      "bi=160, loss=-8.320640563964844\n",
      "bi=170, loss=-5.580193996429443\n",
      "AUC = 0.9899746192893402\n"
     ]
    }
   ],
   "source": [
    "# Start the training process\n",
    "def _mp_fn(rank, flags):\n",
    "    torch.set_default_tensor_type('torch.FloatTensor')\n",
    "    a = run()\n",
    "\n",
    "FLAGS={}\n",
    "xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method='fork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
